{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch.2 Exercises\n",
    "\n",
    "The following exercises are from **Chapter 2: Accessing Text Corpora and Lexical Resources** of the book *Natural Language Processing with Python — Analyzing Text with the Natural Language Toolkit* by Steven Bird, Ewan Klein, and Edward Loper.\n",
    "\n",
    "[[Read Now]](https://www.nltk.org/book/ch02.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.book import *\n",
    "from nltk.corpus import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**\n",
    "\n",
    "☼ Create a variable `phrase` containing a list of words. Review the operations described in the previous chapter, including addition, multiplication, indexing, slicing, and sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = ['forever', 'and', 'always', 'and', 'eternity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phrase + phrase)\n",
    "print(phrase*3)\n",
    "print(phrase[0][:3], phrase[2], phrase[3], phrase[4])\n",
    "print(sorted(set(phrase)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**\n",
    "\n",
    "☼ Use the corpus module to explore `austen-persuasion.txt`. How many word tokens does this book have? How many word types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_persuasion = gutenberg.words('austen-persuasion.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_persuasion[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(austen_persuasion) # word tokens, i.e. each individual sequence of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted(set(austen_persuasion))) # distinct word types, i.e. the set of all unique tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**\n",
    "\n",
    "☼ Use the Brown corpus reader `nltk.corpus.brown.words()` or the Web text corpus reader `nltk.corpus.webtext.words()` to access some sample text in two different genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sci_fi = brown.words(categories=\"science_fiction\")\n",
    "sample_romance = brown.words(categories=\"romance\")\n",
    "\n",
    "for item in [sample_sci_fi, sample_romance]:\n",
    "    print(item[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webtext.words(\"pirates.txt\")[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**\n",
    "\n",
    "☼ Read in the texts of the *State of the Union* addresses, using the `state_union` corpus reader. Count occurrences of `men`, `women`, and `people` in each document. What has happened to the usage of these words over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "state_union_cfd = nltk.ConditionalFreqDist(\n",
    "                    (target, fileid[:4])\n",
    "                    for fileid in state_union.fileids()\n",
    "                    for word in state_union.words(fileid)\n",
    "                    for target in ['men', 'women', 'people']\n",
    "                    if word.lower() == target)\n",
    "\n",
    "state_union_cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word `people` has seen a considerable spike in 1946, around the time of World War II. It also saw a considerable increase between the years of 1991 and 1998, with a peak in 1994 and 1995. The word `men` had a small peak near World War II, but saw considerable use in 1965 and on until 1967, during the Civil Rights Movement. Finally, the term `women` has seen some increase over time, with an obvious upward trend beginning in the mid-1990s, perhaps in tandem with the Third-Wave Feminist Movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**\n",
    "\n",
    "☼ Investigate the holonym-meronym relations for some nouns. Remember that there are three kinds of holonym-meronym relation, so you need to use: `member_meronyms()`, `part_meronyms()`, `substance_meronyms()`, `member_holonyms()`, `part_holonyms()`, and `substance_holonyms()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synsets('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('people.n.01').member_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('people.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('people.n.01').substance_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('people.n.01').part_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('people.n.01').member_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('people.n.01').substance_holonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm having trouble grasping the concept of holonymy and meronymy. From my understanding, a meronym is a component of the current word (a sub-word), and a holonym is a container of the present word (its super-word).\n",
    "\n",
    "After working through `people` as an example, I think I've got a better understanding of it. Now I should be able to think of examples that won't present an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('people.n.01').member_meronyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *person* is a member of the larger group, *people*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('car.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one was easy. Any of the parts of a car are meronyms for the larger object they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('ice.n.01').substance_meronyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! I thought something chemical would get me a good *substance meronym* example. Indeed, ice is made of the substance water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('handle.n.01').part_holonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That got me a lot more results that I thought! I thought *handle* would return *door*, but it didn't. Instead, I got a lot of other objects of which *handle* is a part.\n",
    "\n",
    "Let's see what the components of a door are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('door.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, interesting. This wordnet only has *locks* as being parts of doors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('water.n.01').substance_holonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! I wasn't expecting these words (I was hoping *rain* would be a substance holonym of *water*), but this is such an interesting way to learn about this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset('earth.n.01').member_holonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! I saw *people* as a member of the holonym *world*, so I tried to think of an equivalent concept. EM was just looking through a book of the solar system, so I thought that *earth* might be a member of the holonym *planet*, but *solar system* makes much more sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**\n",
    "\n",
    "☼ In the discussion of comparative wordlists, we created an object called `translate` which you could look up using words in both German and Spanish in order to get corresponding words in English. What problem might arise with this approach? Can you suggest a way to avoid this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, one of the most obvious problems I ran into was that the translation didn't go the other way around. I couldn't pass English words to get the results in Spanish or German. One super easy way to fix this is to add the reverse language pair to the dictionary. However, one problem you'll hit is that you won't be able to specify which language you want to translate it to. The dictionary (as given in the defined function) will overwrite the previous entry when using `update()`. To combat this, you'd want at minimum a dictionary of dictionaries, with languages listed as sub-keys so that one could specify the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**\n",
    "\n",
    "☼ According to Strunk and White's *Elements of Style*, the word *however*, used at the start of a sentence, means \"in whatever way\" or \"to whatever extent\", and not \"nevertheless\". They give this example of correct usage: *However you advise him, he will probably do as he thinks best*. (http://www.bartleby.com/141/strunk3.html) Use the concordance tool to study actual usage of this word in the various texts we have been considering. See also the *LanguageLog* posting \"Fossilized prejudices about 'however'\" at  http://itre.cis.upenn.edu/~myl/languagelog/archives/001913.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the 9 texts available in `from nltk.book import *` and the code `[text].concordance('however')` to pull out instances of *however*, and took a closer look at those coming at the beginning of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.concordance('however')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> However, I picked myself up and hearing a ...\n",
    "> However, I had never been in the South Sea...\n",
    "> However, a good laugh is a mighty good thi...\n",
    "> However, hat and coat and overshoes were o...\n",
    "> However, by dint of beating about a little...\n",
    "> However, a warm savory steam from the kitc...\n",
    "> However, it is always as well to have a lo...\n",
    "> However, my thoughts were at length carrie...\n",
    "> However contracted, that definition is the...\n",
    "\n",
    "Indeed, it appears that Strunk and White's prescription of \"correct\" usage is starkly in contrast to the actual usage of the word. In actuality, *however* at the beginning of a sentence most often means \"nevertheless.\" In only one instance of the above examples does it mean what Strunk and White say it should at sentence start. This goes to show the contrast between prescriptivist notions of language use and actual use by everyday speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**\n",
    "\n",
    "◑ Define a conditional frequency distribution over the Names corpus that allows you to see which initial letters are more frequent for males vs. females (cf. [4.4](https://www.nltk.org/book/ch02.html#fig-cfd-gender))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "        (fileid, name[0])\n",
    "        for fileid in names.fileids()\n",
    "        for name in names.words(fileid))\n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9**\n",
    "\n",
    "◑ Pick a pair of texts and study the differences between them, in terms of vocabulary, vocabulary richness, genre, etc. Can you find pairs of words which have quite different meanings across the two texts, such as *monstrous* in *Moby Dick* and in *Sense and Sensibility*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sense and Sensibility vs. Monty Python and the Holy Grail\n",
    "sense = text2\n",
    "grail = text6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sense), len(grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(sense)), len(set(grail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([w for w in sense if w.isalpha()])), len(set([w for w in grail if w.isalpha()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be comparing *Monty Python and the Holy Grail* vs. *Sense and Sensibility*. Based on simple word counts, it would appear that `python` is much more lexically diverse than `sense`; while *Sense* is nearly 8 times as long, it only uses 3 times as many unique words as Monty Python. Even so, Monty Python itself is still 3 times as unique as Sense overall, with a lexical diversity score of `100 * (2166/16967) = 12.765`, compared to a mere 4% for *Sense*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "sense_content = [w for w in sense if w.lower() not in stopwords and w.isalpha()]\n",
    "grail_content = [w for w in grail if w.lower() not in stopwords and w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_freq = FreqDist(sense_content)\n",
    "\n",
    "sense_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grail_freq = FreqDist(grail_content)\n",
    "\n",
    "grail_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to find the 10 most common words in both texts after removing stopwords and non-alphabetic characters. It appears that both texts are consistent in mainly using pronouns to refer to the main characters. However, I think this is much more evident in the Holy Grail, as it is a screenplay and the character's names are a necessary part of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function given in nltk ch2 4.1 'wordlist corpora'\n",
    "def unusual_words(text):\n",
    "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab = set(w.lower() for w in words.words())\n",
    "    unusual = text_vocab - english_vocab\n",
    "    return sorted(unusual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unusual_sense = unusual_words(sense)\n",
    "unusual_grail = unusual_words(grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(unusual_sense).intersection(unusual_grail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*shrubberies* is a word that appears in both texts!! Oh boy, I can't wait to see what the context is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense.concordance(\"shrubberies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grail.concordance(\"shrubberies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense.common_contexts([\"charged\", \"delighted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grail.common_contexts([\"charged\", \"imprisoned\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believed *charged* would be a good candidate for a word with differing meaning across these two texts. However, upon closer inspection, they appear to be more similar than differing. For instance, Sense returns *charged* as most similar to *delighted*, in the sense of \"am charged with\" and \"am delighted with.\" In comparison, Holy Grail likens *charged* to *imprisoned* by way of \"been charged by\" and \"been imprisoned by\".\n",
    "\n",
    "However, \"am charged with\" and \"been charged by\" are actually much more similar to one another than either is to its common context as provided by nltk. I believe this goes to show how linguistic parsing can be immensely difficult if one simply focuses on syntax and word counts. Pragmatics and a deeper understanding of word meaning are necessary to achieve useful results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10**\n",
    "\n",
    "◑ Read the BBC News article: *UK's Vicky Pollards 'left behind'* http://news.bbc.co.uk/1/hi/education/6173441.stm. The article gives the following statistic about teen language: \"the top 20 words used, including yeah, no, but and like, account for around a third of all words.\" How many word types account for a third of all word tokens, for a variety of text sources? What do you conclude about this statistic? Read more about this on *LanguageLog*, at http://itre.cis.upenn.edu/~myl/languagelog/archives/003993.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_types(text):\n",
    "    results = []\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = [word for word in text if word.isalpha()]\n",
    "    cutoff = len(tokens) / 3 # Looking for a third of all word tokens, so stop at this value\n",
    "    \n",
    "    # Create frequency distro\n",
    "    types = sorted(FreqDist(tokens).items(), key=lambda kv: kv[1], reverse=True)\n",
    "    \n",
    "    # Get candidates\n",
    "    for k, v in types:\n",
    "         if cutoff > 0: # Until the cutoff is reached\n",
    "            results.append(k)\n",
    "            cutoff -= v\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text1, text2, text3, text4, text5, text7, text8, text9]\n",
    "top = 0\n",
    "\n",
    "for text in texts:\n",
    "    types = third_types(text)\n",
    "    top += len(types)\n",
    "    print(text, types, len(types))\n",
    "\n",
    "print(top/9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this statistic is valid, but may be misguided. According to the brief analysis done here, about 20 words should count for a third of all word tokens in a *variety* of genres and types of literature. This suggests that British teen's vocabulary is not lacking in any way; indeed, they appear to be following an inherent pattern of language. I'd recommend the author look into the Pareto principle, which may help to explain why a large portion of the next is taken up by a small number of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11**\n",
    "\n",
    "◑ Investigate the table of modal distributions and look for other patterns. Try to explain them in terms of your own impressionistic understanding of the different genres. Can you find other closed classes of words that exhibit significant differences across different genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n",
      "          humor    16    30     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "        (genre, word)\n",
    "        for genre in brown.categories()\n",
    "        for word in brown.words(categories=genre))\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll focus on the most frequent modal in each genre, and what my impressionistic understanding is. We've already noted that the most frequent in \"news\" is *will*, which I believe may have something to do with reporting on current events and offering updates on future developments. We've also seen \"romance\" with most frequent *could*, which I believe is tied to the suggestive and hopeful nature of the genre. \"Religion\" is tied closely between \"can\" and \"may\", which I believe is highly connected to the notions of obedience and restraint present in the genre.\n",
    "\n",
    "\"Hobbies\" is most interesting to me, with a close tie between \"can\" and \"will.\" I think the notion of a \"can-do\" attitude is present here, as well as instructions on what will happen when one follows, for example, a DIY project plan. \"Science fiction\" is pretty low on the modals completely, which I might say has to do with the genre's focus on factual information, instead of suggestive or possible interpretations of events. Finally, \"humor\" is also low on modals, again probably due to a focus on presency and immediacy.\n",
    "\n",
    "One class of closed words that is making the rounds these days is pronouns, due to the surge in interest in LGBTQ+ issues. I'd like to examine this closed class of words next, and see what patterns I might find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   I  you  she   he   it   we they   me  you  her  him   us them \n",
      "           news  179   55   42  451  363   77  205   29   55  103   93   12   96 \n",
      "       religion  155  100   10  137  264  176  115   31  100    8   60   59   74 \n",
      "        hobbies  154  383   21  155  476  100  177   16  383   16   49   23  127 \n",
      "science_fiction   98   81   36  139  129   30   53   20   81   71   58    6   47 \n",
      "        romance  951  456  496  702  573   78  168  193  456  651  339   42  142 \n",
      "          humor  239  131   58  146  162   32   70   56  131   62   48   23   49 \n"
     ]
    }
   ],
   "source": [
    "pronouns = [\"I\", \"you\", \"she\", \"he\", \"it\", \"we\", \"they\", \"me\", \"you\", \"her\", \"him\", \"us\", \"them\"]\n",
    "\n",
    "cfd.tabulate(conditions=genres, samples=pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very interesting! Alright, from the top...\n",
    "\n",
    "**News** shows \"he\" as the most-used pronoun, and \"us\" as the least-used. At the time of the compilation of this corpus, it may not be inaccurate to say that most politicians are male, and therefore most news would reference the masculine pronoun. In addition, news is rarely put forth by an explicit group, so the notion of plurality should be nonexistent.\n",
    "\n",
    "**Religion** has \"it\" as the most popular pronoun, as well as \"hobbies.\" I'm not sure why religion focuses so much on \"it\", but I do know that hobbies are focused mostly on objects and things, so this seems natural for that genre.\n",
    "\n",
    "**Science Fiction** has \"he\" as the most popular, followed by \"it.\" I see this as the tendency to have a mostly male cast, as well as for there to be strange and alien agents that characters run into that can only be referred to as \"it.\"\n",
    "\n",
    "**Humor** has \"I\" as the most popular pronoun, which can be a result of comedians using themselves as a jumping-off point for their comedic acts.\n",
    "\n",
    "**Romance** has the highest pronoun count of all, which reflects the genre's focus on relationships. \"I\" is the most popular with a staggering count of 951, a clear reflection of the genre's focus on the main character's inner thoughts and feelings. The next most popular pronouns are \"he\" and \"her,\" and I think the subject-object distinction is vitally important here. As the main character tends to be a heroine, her love interest would naturally be referred to as \"he\" and herself as \"her,\" as she is the object of his affections, and is thus on the receiving end of any action initiated by him."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12**\n",
    "\n",
    "◑ The CMU Pronouncing Dictionary contains multiple pronunciations for certain words. How many distinct words does it contain? What fraction of words in this dictionary have more than one possible pronunciation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13**\n",
    "\n",
    "◑ What percentage of noun synsets have no hyponyms? You can get all noun synsets using `wn.all_synsets('n')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 14**\n",
    "\n",
    "◑ Define a function `supergloss(s)` that takes a synset `s` as its argument and returns a string consisting of the concatenation of the definition of `s`, and the definitions of all the hypernyms and hyponyms of `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 15**\n",
    "\n",
    "◑ Write a program to find all words that occur at least three times in the Brown Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 16**\n",
    "\n",
    "◑ Write a program to generate a table of lexical diversity scores (i.e. token/type ratios), as we saw in [1.1](https://www.nltk.org/book/ch01.html#tab-brown-types). Include the full set of Brown Corpus genres (`nltk.corpus.brown.categories()`). Which genre has the lowest diversity (greatest number of tokens per type)? Is this what you would have expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 17**\n",
    "\n",
    "◑ Write a function that finds the 50 most frequently occurring words of a text that are not stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 18**\n",
    "\n",
    "◑ Write a program to print the 50 most frequent bigrams (pairs of adjacent words) of a text, omitting bigrams that contain stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 19**\n",
    "\n",
    "◑ Write a program to create a table of word frequencies by genre, like the one given in [1](https://www.nltk.org/book/ch02.html#sec-extracting-text-from-corpora) for modals. Choose your own words and try to find words whose presence (or absence) is typical of a genre. Discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 20**\n",
    "\n",
    "◑ Write a function `word_freq()` that takes a word and the name of a section of the Brown Corpus as arguments, and computes the frequency of the word in that section of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 21**\n",
    "\n",
    "◑ Write a program to guess the number of syllables contained in a text, making use of the CMU Pronouncing Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 22**\n",
    "\n",
    "◑ Define a function `hedge(text)` which processes a text and produces a new version with the word `'like'` between every third word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 23a**\n",
    "\n",
    "★ Zipf's Law: Let *f(w)* be the frequency of a word w in free text. Suppose that all the words of a text are ranked according to their frequency, with the most frequent word first. Zipf's law states that the frequency of a word type is inversely proportional to its rank (i.e. *f × r = k*, for some constant *k*). For example, the 50th most common word type should occur three times as frequently as the 150th most common word type.\n",
    "\n",
    "Write a function to process a large text and plot word frequency against word rank using `pylab.plot`. Do you confirm Zipf's law? (Hint: it helps to use a logarithmic scale). What is going on at the extreme ends of the plotted line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 23b**\n",
    "\n",
    "★ Generate random text, e.g., using `random.choice(\"abcdefg \")`, taking care to include the space character. You will need to `import` random first. Use the string concatenation operator to accumulate characters into a (very) long string. Then tokenize this string, and generate the Zipf plot as before, and compare the two plots. What do you make of Zipf's Law in the light of this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 24a**\n",
    "\n",
    "★ Modify the text generation program in [2.2](https://www.nltk.org/book/ch02.html#code-random-text) further, to do the following tasks:\n",
    "\n",
    "Store the `n` most likely words in a list words then randomly choose a word from the list using `random.choice()`. (You will need to `import` random first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 24b**\n",
    "\n",
    "★ Select a particular genre, such as a section of the Brown Corpus, or a genesis translation, one of the Gutenberg texts, or one of the Web texts. Train the model on this corpus and get it to generate random text. You may have to experiment with different start words. How intelligible is the text? Discuss the strengths and weaknesses of this method of generating random text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 24c**\n",
    "\n",
    "★ Now train your system using two distinct genres and experiment with generating text in the hybrid genre. Discuss your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 25**\n",
    "\n",
    "★ Define a function find_language() that takes a string as its argument, and returns a list of languages that have that string as a word. Use the udhr corpus and limit your searches to files in the Latin-1 encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 26**\n",
    "\n",
    "★ What is the branching factor of the noun hypernym hierarchy? I.e. for every noun synset that has hyponyms — or children in the hypernym hierarchy — how many do they have on average? You can get all noun synsets using `wn.all_synsets('n')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 27**\n",
    "\n",
    "★ The polysemy of a word is the number of senses it has. Using WordNet, we can determine that the noun *dog* has 7 senses with: `len(wn.synsets('dog', 'n'))`. Compute the average polysemy of nouns, verbs, adjectives and adverbs according to WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 28**\n",
    "\n",
    "★ Use one of the predefined similarity measures to score the similarity of each of the following pairs of words. Rank the pairs in order of decreasing similarity. How close is your ranking to the order given here, an order that was established experimentally by [(Miller & Charles, 1998)](https://www.nltk.org/book/bibliography.html#millercharles1998): car-automobile, gem-jewel, journey-voyage, boy-lad, coast-shore, asylum-madhouse, magician-wizard, midday-noon, furnace-stove, food-fruit, bird-cock, bird-crane, tool-implement, brother-monk, lad-brother, crane-implement, journey-car, monk-oracle, cemetery-woodland, food-rooster, coast-hill, forest-graveyard, shore-woodland, monk-slave, coast-forest, lad-wizard, chord-smile, glass-magician, rooster-voyage, noon-string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
